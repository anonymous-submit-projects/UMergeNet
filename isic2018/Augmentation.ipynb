{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7267644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import config\n",
    "import sys\n",
    "import cv2\n",
    "sys.path.append('../util')\n",
    "from DatasetAugmentation import *\n",
    "\n",
    "\n",
    "#Insira o nome do root do dataset original\n",
    "original_dataset_path = '/mnt/TUDAO/DocNanoNet/ISIC2018/datasets/isic2018-original'\n",
    "output_base = config.dataset_path\n",
    "\n",
    "# -----------------------------\n",
    "# Parâmetros\n",
    "# -----------------------------\n",
    "N = 1  # número de aumentações\n",
    "num_to_valid = 0    # número de imagens a mover do train para valid\n",
    "num_to_test  = 0    # número de imagens a mover do train para test\n",
    "\n",
    "\n",
    "target_size  = (256, 256)\n",
    "random.seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# Caminhos de entrada e saída\n",
    "# -----------------------------\n",
    "orig_train_img_dir  = os.path.join(original_dataset_path, 'ISIC2018_Task1-2_Training_Input')\n",
    "orig_train_mask_dir = os.path.join(original_dataset_path, 'ISIC2018_Task1_Training_GroundTruth')\n",
    "orig_valid_img_dir  = os.path.join(original_dataset_path, 'ISIC2018_Task1-2_Validation_Input')\n",
    "orig_valid_mask_dir = os.path.join(original_dataset_path, 'ISIC2018_Task1_Validation_GroundTruth')\n",
    "orig_test_img_dir   = os.path.join(original_dataset_path, 'ISIC2018_Task1-2_Test_Input')\n",
    "orig_test_mask_dir  = os.path.join(original_dataset_path, 'ISIC2018_Task1_Test_GroundTruth')\n",
    "\n",
    "\n",
    "\n",
    "output_dirs = {\n",
    "    'train_images': os.path.join(output_base, 'images/train'),\n",
    "    'train_labels': os.path.join(output_base, 'labels/train'),\n",
    "    'valid_images': os.path.join(output_base, 'images/valid'),\n",
    "    'valid_labels': os.path.join(output_base, 'labels/valid'),\n",
    "    'test_images':  os.path.join(output_base, 'images/test'),\n",
    "    'test_labels':  os.path.join(output_base, 'labels/test'),\n",
    "}\n",
    "\n",
    "transforms = A.Compose([\n",
    "    A.Resize(*target_size, interpolation=cv2.INTER_NEAREST),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.7, border_mode=cv2.BORDER_REFLECT),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.ElasticTransform(p=0.2),\n",
    "    A.GaussianBlur(p=0.3),\n",
    "    A.GridDistortion(p=0.2),\n",
    "])\n",
    "\n",
    "\n",
    "augment_dataset(N, num_to_valid, num_to_test,\n",
    "                    orig_train_img_dir, orig_train_mask_dir,\n",
    "                    orig_valid_img_dir, orig_valid_mask_dir,\n",
    "                    orig_test_img_dir, orig_test_mask_dir,\n",
    "                    output_base,\n",
    "                    transforms,\n",
    "                    mask_suffix='_segmentation'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7402de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch5070",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
