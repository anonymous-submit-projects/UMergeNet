{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d22eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter nbconvert --to script DatasetAugmentation.ipynb\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "images_extensions = ('.png', '.jpg', '.jpeg', '.bmp')\n",
    "\n",
    "# -----------------------------\n",
    "# Funções auxiliares\n",
    "# -----------------------------\n",
    "\n",
    "def copy_and_fix(img_src_dir, mask_src_dir, img_out_dir, mask_out_dir, selected_files=None, \n",
    "                 function_to_apply_to_masks=None, mask_suffix=''):\n",
    "    \"\"\"\n",
    "    Copia imagens e máscaras de img_src_dir/mask_src_dir para img_out_dir/mask_out_dir.\n",
    "    Se selected_files for None, copia todos os arquivos da pasta de origem.\n",
    "    Aceita máscaras com qualquer extensão (.png, .jpg, .jpeg .bmp).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(img_src_dir) or not os.path.exists(mask_src_dir):\n",
    "        return 0  # nada para copiar\n",
    "    \n",
    "    os.makedirs(img_out_dir, exist_ok=True)\n",
    "    os.makedirs(mask_out_dir, exist_ok=True)\n",
    "    \n",
    "    if selected_files is None:\n",
    "        files = sorted([f for f in os.listdir(img_src_dir) if f.lower().endswith(images_extensions)])\n",
    "    else:\n",
    "        files = selected_files\n",
    "    \n",
    "    count = 0\n",
    "    for f in tqdm(files, desc=f\"Copiando {os.path.basename(img_out_dir)}\"):\n",
    "        img_src = os.path.join(img_src_dir, f)\n",
    "        base = os.path.splitext(f)[0]\n",
    "\n",
    "        # procurar a máscara com qualquer extensão\n",
    "        possible_mask_paths = [\n",
    "            os.path.join(mask_src_dir, base + mask_suffix + ext)\n",
    "            for ext in images_extensions\n",
    "        ]\n",
    "        mask_src = next((p for p in possible_mask_paths if os.path.exists(p)), None)\n",
    "\n",
    "        if mask_src and os.path.exists(img_src):\n",
    "            # Copia imagem\n",
    "            shutil.copy(img_src, os.path.join(img_out_dir, base + \".png\"))\n",
    "            # Copia máscara, convertendo pra PNG\n",
    "            mask = np.array(Image.open(mask_src).convert(\"L\"))\n",
    "            if function_to_apply_to_masks is not None:\n",
    "                #Aplica a funcao de correcao\n",
    "                mask = function_to_apply_to_masks(mask)\n",
    "            Image.fromarray(mask).save(os.path.join(mask_out_dir, base + \".png\"))\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Augmentation para treino\n",
    "# -----------------------------\n",
    "def augment_train_images(image_list, image_dir, mask_dir, output_image_dir, output_mask_dir, transforms, N, \n",
    "                         function_to_apply_to_masks=None, mask_suffix=''):\n",
    "    for img_name in tqdm(image_list, desc=\"Aumentando imagens de treino\"):\n",
    "        # Nome base sem extensão\n",
    "        base_name = os.path.splitext(img_name)[0]\n",
    "\n",
    "        # Caminhos possíveis (.png, .jpg, .jpeg)\n",
    "        possible_img_paths = [\n",
    "            os.path.join(image_dir, base_name + ext) for ext in images_extensions\n",
    "        ]\n",
    "        possible_mask_paths = [\n",
    "            os.path.join(mask_dir, base_name + mask_suffix + ext) for ext in images_extensions\n",
    "        ]\n",
    "        \n",
    "        # Escolhe o primeiro arquivo que existir\n",
    "        img_path = next((p for p in possible_img_paths if os.path.exists(p)), None)\n",
    "        mask_path = next((p for p in possible_mask_paths if os.path.exists(p)), None)\n",
    "\n",
    "        if img_path is None or mask_path is None:\n",
    "            print(f\"[AVISO] Arquivo não encontrado para {base_name}. Pulando.\")\n",
    "            print(possible_mask_paths)\n",
    "            continue\n",
    "\n",
    "        # Lê imagem e máscara\n",
    "        image = cv2.imread(img_path)\n",
    "        mask  = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if function_to_apply_to_masks is not None:\n",
    "            mask  = function_to_apply_to_masks(mask)\n",
    "        \n",
    "            \n",
    "        if image is None or mask is None:\n",
    "            print(f\"[AVISO] Falha ao ler {base_name}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        # Transforma e salva versão original como PNG\n",
    "        orig = transforms(image=image, mask=mask)\n",
    "        cv2.imwrite(os.path.join(output_image_dir, f\"{base_name}_orig.png\"), orig['image'])\n",
    "        cv2.imwrite(os.path.join(output_mask_dir, f\"{base_name}_orig.png\"), orig['mask'])\n",
    "\n",
    "        # Gera augmentations\n",
    "        for i in range(N):\n",
    "            aug = transforms(image=image, mask=mask)\n",
    "            cv2.imwrite(os.path.join(output_image_dir, f\"{base_name}_aug{i}.png\"), aug['image'])\n",
    "            cv2.imwrite(os.path.join(output_mask_dir, f\"{base_name}_aug{i}.png\"), aug['mask'])\n",
    "\n",
    "\n",
    "\n",
    "def augment_dataset(N, num_to_valid, num_to_test,  \n",
    "                    orig_train_img_dir, orig_train_mask_dir,\n",
    "                    orig_valid_img_dir, orig_valid_mask_dir,\n",
    "                    orig_test_img_dir, orig_test_mask_dir,\n",
    "                    output_base,\n",
    "                    transforms,\n",
    "                    function_to_apply_to_masks=None,\n",
    "                    mask_suffix=''):\n",
    "\n",
    "    output_dirs = {\n",
    "        'train_images': os.path.join(output_base, 'images/train'),\n",
    "        'train_labels': os.path.join(output_base, 'labels/train'),\n",
    "        'valid_images': os.path.join(output_base, 'images/valid'),\n",
    "        'valid_labels': os.path.join(output_base, 'labels/valid'),\n",
    "        'test_images':  os.path.join(output_base, 'images/test'),\n",
    "        'test_labels':  os.path.join(output_base, 'labels/test'),\n",
    "    }\n",
    "\n",
    "    # -----------------------------\n",
    "    # Selecionar imagens para splits\n",
    "    # -----------------------------\n",
    "    all_images = sorted([f for f in os.listdir(orig_train_img_dir) if f.lower().endswith(images_extensions)])\n",
    "    total_imgs = len(all_images)\n",
    "\n",
    "    if num_to_valid + num_to_test >= total_imgs:\n",
    "        print(\"num_to_valid:\",num_to_valid, \"num_to_test:\", num_to_test, \"total_imgs:\",total_imgs)\n",
    "        raise ValueError(\"Quantidade de imagens para valid+test é maior ou igual ao total disponível.\")\n",
    "\n",
    "    # Amostras aleatórias (sem modificar o diretório original)\n",
    "    selected_test = set(random.sample(all_images, num_to_test))\n",
    "    remaining = [f for f in all_images if f not in selected_test]\n",
    "\n",
    "    selected_valid = set(random.sample(remaining, num_to_valid))\n",
    "    remaining = [f for f in remaining if f not in selected_valid]\n",
    "\n",
    "    train_images = remaining\n",
    "\n",
    "    # -----------------------------\n",
    "    # Estimativa total de imagens geradas\n",
    "    # -----------------------------\n",
    "    train_total = len(train_images)\n",
    "    total_output = train_total * (N + 1)\n",
    "\n",
    "    print(f\"Imagens totais no dataset original: {total_imgs}\")\n",
    "    print(f\"→ Treino: {len(train_images)}\")\n",
    "    print(f\"→ Validação (do treino): {len(selected_valid)}\")\n",
    "    print(f\"→ Teste (do treino): {len(selected_test)}\")\n",
    "    print(f\"\\nCom N={N}, total de imagens geradas no treino será: {total_output}\")\n",
    "\n",
    "    choice = input(\"Deseja prosseguir? (y/n): \").strip().lower()\n",
    "    if choice not in ('y', 's'):\n",
    "        print(\"Processo cancelado.\")\n",
    "        raise SystemExit\n",
    "\n",
    "    # -----------------------------\n",
    "    # Criação das pastas\n",
    "    # -----------------------------\n",
    "    if any(os.path.exists(d) for d in output_dirs.values()):\n",
    "        print(\"O diretório de saída já existe. Abortando para evitar sobrescrita.\")\n",
    "        raise SystemExit\n",
    "    else:\n",
    "        for d in output_dirs.values():\n",
    "            os.makedirs(d, exist_ok=True)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # Copiar pastas existentes de valid/test\n",
    "    # -----------------------------\n",
    "    count_valid_existing = copy_and_fix(orig_valid_img_dir, orig_valid_mask_dir,\n",
    "                                        output_dirs['valid_images'], output_dirs['valid_labels'],\n",
    "                                        function_to_apply_to_masks=function_to_apply_to_masks, mask_suffix=mask_suffix)\n",
    "    count_test_existing  = copy_and_fix(orig_test_img_dir, orig_test_mask_dir,\n",
    "                                        output_dirs['test_images'], output_dirs['test_labels'],\n",
    "                                        function_to_apply_to_masks=function_to_apply_to_masks, mask_suffix=mask_suffix)\n",
    "\n",
    "    print(f\"→ {count_valid_existing} imagens copiadas da pasta valid original.\")\n",
    "    print(f\"→ {count_test_existing} imagens copiadas da pasta test original.\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Mover imagens do train para valid/test se num_to_valid/num_to_test > 0\n",
    "    # -----------------------------\n",
    "    # Valid\n",
    "    if num_to_valid > 0:\n",
    "        selected_valid = list(selected_valid)\n",
    "        copied = copy_and_fix(orig_train_img_dir, orig_train_mask_dir,\n",
    "                            output_dirs['valid_images'], output_dirs['valid_labels'], selected_valid,\n",
    "                            function_to_apply_to_masks=function_to_apply_to_masks, mask_suffix=mask_suffix)\n",
    "        print(f\"→ {copied} imagens copiadas do train para valid.\")\n",
    "\n",
    "    # Test\n",
    "    if num_to_test > 0:\n",
    "        selected_test = list(selected_test)\n",
    "        copied = copy_and_fix(orig_train_img_dir, orig_train_mask_dir,\n",
    "                            output_dirs['test_images'], output_dirs['test_labels'], selected_test,\n",
    "                            function_to_apply_to_masks=function_to_apply_to_masks, mask_suffix=mask_suffix)\n",
    "        print(f\"→ {copied} imagens copiadas do train para test.\")\n",
    "\n",
    "    \n",
    "\n",
    "    # -----------------------------\n",
    "    # Processar o conjunto de treino\n",
    "    # -----------------------------\n",
    "    augment_train_images(train_images, orig_train_img_dir, orig_train_mask_dir,\n",
    "                    output_dirs['train_images'], output_dirs['train_labels'],\n",
    "                    transforms, N,\n",
    "                    function_to_apply_to_masks=function_to_apply_to_masks, mask_suffix=mask_suffix)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Relatório final\n",
    "    # -----------------------------\n",
    "    def count_images_in_dir(directory):\n",
    "        return len([f for f in os.listdir(directory) if f.lower().endswith(images_extensions)])\n",
    "\n",
    "    print(\"\\nResumo final:\")\n",
    "    for key, path in output_dirs.items():\n",
    "        print(f\"{key}: {count_images_in_dir(path)} arquivos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de79a984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagens totais no dataset original: 38\n",
      "→ Treino: 28\n",
      "→ Validação (do treino): 5\n",
      "→ Teste (do treino): 5\n",
      "\n",
      "Com N=2, total de imagens geradas no treino será: 84\n",
      "→ 0 imagens copiadas da pasta valid original.\n",
      "→ 0 imagens copiadas da pasta test original.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copiando valid: 100%|██████████| 5/5 [00:00<00:00, 389.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ 5 imagens copiadas do train para valid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copiando test: 100%|██████████| 5/5 [00:00<00:00, 434.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ 5 imagens copiadas do train para test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aumentando imagens de treino: 100%|██████████| 28/28 [00:00<00:00, 29.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo final:\n",
      "train_images: 84 arquivos\n",
      "train_labels: 84 arquivos\n",
      "valid_images: 5 arquivos\n",
      "valid_labels: 5 arquivos\n",
      "test_images: 5 arquivos\n",
      "test_labels: 5 arquivos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #Uma classe para simular o arquivo config presente em cada dataset\n",
    "    class Config:\n",
    "        pass\n",
    "\n",
    "    config = Config()\n",
    "    config.dataset_path          = \"/mnt/TUDAO/0PequeNet/DatasetAugmentationTest/AugmentationTest\"\n",
    "    config.original_dataset_path = \"/mnt/TUDAO/0PequeNet/medetec/datasets/Medetec_foot_ulcer_224\"\n",
    "    config.dataset_resolution    = 224\n",
    "\n",
    "    # -----------------------------\n",
    "    # Parâmetros\n",
    "    # -----------------------------\n",
    "    N = 2  # número de aumentações\n",
    "    num_to_valid = 5  # número de imagens a mover do train para valid\n",
    "    num_to_test  = 5  # número de imagens a mover do train para test\n",
    "    target_size  = (config.dataset_resolution, config.dataset_resolution)\n",
    "    random.seed(42)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Caminhos de entrada e saída\n",
    "    # -----------------------------\n",
    "    orig_train_img_dir  = os.path.join(config.original_dataset_path, 'train/images')\n",
    "    orig_train_mask_dir = os.path.join(config.original_dataset_path, 'train/labels')\n",
    "    orig_valid_img_dir  = os.path.join(config.original_dataset_path, 'valid/images')\n",
    "    orig_valid_mask_dir = os.path.join(config.original_dataset_path, 'valid/labels')\n",
    "    orig_test_img_dir   = os.path.join(config.original_dataset_path, 'test/images')\n",
    "    orig_test_mask_dir  = os.path.join(config.original_dataset_path, 'test/labels')\n",
    "\n",
    "\n",
    "    output_base = config.dataset_path\n",
    "\n",
    "    # -----------------------------\n",
    "    # Transformações de aumento\n",
    "    # -----------------------------\n",
    "    transforms = A.Compose([\n",
    "        A.Resize(*target_size, interpolation=cv2.INTER_NEAREST),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        #A.VerticalFlip(p=0.5),\n",
    "        #A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.7, border_mode=cv2.BORDER_REFLECT),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.ElasticTransform(p=0.2),\n",
    "        A.GaussianBlur(p=0.3),\n",
    "        A.GridDistortion(p=0.2),\n",
    "    ])\n",
    "\n",
    "    augment_dataset(N, num_to_valid, num_to_test,\n",
    "                    orig_train_img_dir, orig_train_mask_dir,\n",
    "                    orig_valid_img_dir, orig_valid_mask_dir,\n",
    "                    orig_test_img_dir, orig_test_mask_dir,\n",
    "                    output_base,\n",
    "                    transforms)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch5070",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
