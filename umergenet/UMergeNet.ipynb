{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17da036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from enum import Enum\n",
    "\n",
    "from util import count_trainable_parameters\n",
    "#jupyter nbconvert --to script UMergeNet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76edf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "#MELHOR VERSAO ATE O MOMENTO (15/10 12:00)\n",
    "class AdjustChannels(nn.Module):\n",
    "    \"\"\"\n",
    "    Ajusta o número de canais de um tensor:\n",
    "    - Se in_ch < out_ch: repete canais até atingir out_ch\n",
    "    - Se in_ch > out_ch: mantém (out_ch//2) canais e reduz o restante com uma conv1x1 para (out_ch - keep)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "\n",
    "        if in_ch > out_ch:\n",
    "            self.keep = out_ch // 2\n",
    "            self.reduced_out = out_ch - self.keep\n",
    "            self.reduce = nn.Conv2d(in_ch - self.keep, self.reduced_out, kernel_size=1)\n",
    "        else:\n",
    "            self.reduce = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "\n",
    "        if c == self.out_ch:\n",
    "            return x\n",
    "\n",
    "        elif c < self.out_ch:\n",
    "            repeat_factor = -(-self.out_ch // c)  # ceil(out_ch / c)\n",
    "            return x.repeat(1, repeat_factor, 1, 1)[:, :self.out_ch]\n",
    "\n",
    "        else:  # c > out_ch\n",
    "            part1 = x[:, :self.keep]\n",
    "            excess = x[:, self.keep:]\n",
    "            reduced = self.reduce(excess)\n",
    "            return torch.cat([part1, reduced], dim=1)\n",
    "\n",
    "\n",
    "class AxialConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=7, dilation = 1, groups=1, bias=True, padding='same'):\n",
    "        super().__init__()\n",
    "        self.adjust = AdjustChannels(in_channels, out_channels)\n",
    "        \n",
    "        self.groups       = groups\n",
    "        self.out_channels = out_channels\n",
    "        if groups == out_channels: #DW\n",
    "            self.dw_h   = nn.Conv2d(out_channels, out_channels, kernel_size=(kernel_size, 1), padding=padding, groups=groups, dilation=dilation, bias=bias)\n",
    "            self.dw_w   = nn.Conv2d(out_channels, out_channels, kernel_size=(1, kernel_size), padding=padding, groups=groups, dilation=dilation, bias=bias)\n",
    "        else:    \n",
    "            self.dw_h   = nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size, 1), padding=padding, groups=groups, dilation=dilation, bias=bias)\n",
    "            self.dw_w   = nn.Conv2d(in_channels, out_channels, kernel_size=(1, kernel_size), padding=padding, groups=groups, dilation=dilation, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.groups == self.out_channels:\n",
    "            # (Caso seja DepthWise)\n",
    "            x = self.adjust(x)\n",
    "            x = x + self.dw_h(x) + self.dw_w(x)\n",
    "        else:\n",
    "            x = self.adjust(x) + self.dw_h(x) + self.dw_w(x)\n",
    "        return x\n",
    "    \n",
    "class ConvType(Enum):\n",
    "    Axial    = 0\n",
    "    Atrous   = 1\n",
    "    Standard = 2\n",
    "    Normal   = 2\n",
    "    \n",
    "def conv(type, in_channels, out_channels, kernel_size, dilation=1, padding='same', groups=1):\n",
    "    if type == ConvType.Axial:\n",
    "        return AxialConv(in_channels, out_channels, kernel_size=kernel_size, padding=padding, groups=groups)\n",
    "    if type == ConvType.Atrous:\n",
    "        #7 becomes 5\n",
    "        kernel_size -= 2\n",
    "        #1 becomes 2\n",
    "        dilation    += 1\n",
    "        return nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, dilation=dilation, padding='same', groups=groups)\n",
    "    else:\n",
    "        return nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, dilation=dilation, padding='same', groups=groups)\n",
    "\n",
    "class EncoderTwoLanesBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_type, groups=1):\n",
    "        super().__init__()\n",
    "        middle_channels = out_channels//2\n",
    "\n",
    "        if groups == 'dw':\n",
    "            groups = middle_channels\n",
    "\n",
    "        self.wide   = nn.Sequential()\n",
    "        self.narrow = nn.Sequential()\n",
    "\n",
    "        self.wide.append(conv(conv_type, in_channels, middle_channels, kernel_size=7, padding='same', groups=groups))\n",
    "        self.narrow.append(nn.Conv2d(    in_channels, middle_channels, kernel_size=3, padding='same', groups=groups))\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.pw = nn.Conv2d(out_channels, out_channels, kernel_size=1, padding='same')\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat([self.wide(x), self.narrow(x)], dim=1)\n",
    "        x = self.act(self.pw(self.bn(x)))\n",
    "        return x\n",
    "\n",
    "class DecoderTwoLanesBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_type, groups=1):\n",
    "        super().__init__()\n",
    "        middle_channels = out_channels//2\n",
    "\n",
    "        if groups == 'dw':\n",
    "            groups = middle_channels\n",
    "\n",
    "        \n",
    "        self.pw1    = nn.Conv2d(in_channels, middle_channels, kernel_size=1, padding='same')\n",
    "        self.wide   = nn.Sequential()\n",
    "        self.narrow = nn.Sequential()\n",
    "\n",
    "        self.wide.append(conv(conv_type, middle_channels, middle_channels, kernel_size=7, padding='same', groups=groups))\n",
    "        self.narrow.append(    nn.Conv2d(middle_channels, middle_channels, kernel_size=3, padding='same', groups=groups))\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.pw2 = nn.Conv2d(out_channels, out_channels, kernel_size=1, padding='same')\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pw1(x)\n",
    "        x = torch.cat([self.wide(x), self.narrow(x)], dim=1)\n",
    "        x = self.act(self.pw2(self.bn(x)))\n",
    "        return x\n",
    "\n",
    "class MergerBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_layers, conv_type, groups=4):\n",
    "        super().__init__()\n",
    "\n",
    "        if groups == 'dw':\n",
    "            groups = out_channels\n",
    "        \n",
    "\n",
    "        self.pw1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding='same')\n",
    "        self.convs = nn.Sequential()\n",
    "        for i in range(1):\n",
    "            self.convs.append(conv(conv_type, out_channels, out_channels, kernel_size=7, padding='same', groups=groups))\n",
    "            self.convs.append(nn.BatchNorm2d(out_channels))\n",
    "            self.convs.append(nn.Conv2d(out_channels, out_channels, kernel_size=1, padding='same'))\n",
    "            self.convs.append(nn.GELU())\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            self.convs.append(conv(conv_type, out_channels, out_channels, kernel_size=7, padding='same', groups=groups))\n",
    "            self.convs.append(nn.BatchNorm2d(out_channels))\n",
    "            self.convs.append(nn.Conv2d(out_channels, out_channels, kernel_size=1, padding='same'))\n",
    "            self.convs.append(nn.GELU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pw1(x)\n",
    "        x = self.convs(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UMergeNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, layer1=16, layer2=32, layer3=64, layer4=128, layer5=256,\n",
    "                       encoder_groups=4, merger_groups=4, decoder_groups=4, conv_type=ConvType.Axial):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pool         = nn.MaxPool2d(kernel_size=2)\n",
    "        self.upsample     = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = EncoderTwoLanesBlock(in_channels,  layer1,                        conv_type=conv_type)\n",
    "        self.enc2 = EncoderTwoLanesBlock(layer1,       layer2, groups=encoder_groups, conv_type=conv_type)\n",
    "        self.enc3 = EncoderTwoLanesBlock(layer2,       layer3, groups=encoder_groups, conv_type=conv_type)\n",
    "        self.enc4 = EncoderTwoLanesBlock(layer3,       layer4, groups=encoder_groups, conv_type=conv_type)\n",
    "        self.enc5 = EncoderTwoLanesBlock(layer4,       layer5, groups=encoder_groups, conv_type=conv_type)\n",
    "\n",
    "        # Mergers\n",
    "        self.merge1 = MergerBlock(layer1 + layer2 + layer3 + in_channels, layer3,   num_layers=0, groups=merger_groups, conv_type=conv_type)\n",
    "        self.merge2 = MergerBlock(layer3 + layer4 + in_channels, layer4,            num_layers=1, groups=merger_groups, conv_type=conv_type)\n",
    "        self.merge3 = MergerBlock(layer4 + layer5 + in_channels, layer5,            num_layers=2, groups=merger_groups, conv_type=conv_type)\n",
    "\n",
    "        # Decoder\n",
    "        self.dec5 = DecoderTwoLanesBlock(layer5*2,           layer5, groups=decoder_groups, conv_type=conv_type)\n",
    "        self.dec4 = DecoderTwoLanesBlock(layer5+layer4*2,    layer4, groups=decoder_groups, conv_type=conv_type)\n",
    "        self.dec3 = DecoderTwoLanesBlock(layer4+layer3*2,    layer3, groups=decoder_groups, conv_type=conv_type)\n",
    "        self.dec2 = DecoderTwoLanesBlock(layer3+layer2,      layer2, groups=decoder_groups, conv_type=conv_type)\n",
    "        self.dec1 = DecoderTwoLanesBlock(layer2+layer1,      layer1, groups=decoder_groups, conv_type=conv_type)\n",
    "\n",
    "        # Final Layer\n",
    "        self.final    = nn.Conv2d(layer1, out_channels, kernel_size=1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        ## Encoder\n",
    "        lo1 = self.enc1(x)\n",
    "        lo1_resized = self.pool(lo1)\n",
    "\n",
    "        x1  = self.pool(x)\n",
    "        lo2 = self.enc2(lo1_resized)\n",
    "        lo2_resized = self.pool(lo2)\n",
    "\n",
    "        x2  = self.pool(x1)\n",
    "        lo3 = self.enc3(lo2_resized)\n",
    "\n",
    "        x3  = self.pool(x2)\n",
    "        lo4 = self.enc4(self.pool(lo3))\n",
    "\n",
    "        x4  = self.pool(x3)\n",
    "        lo5 = self.enc5(self.pool(lo4))\n",
    "\n",
    "        # Mergers\n",
    "        lo_features = torch.cat((x2, self.pool(lo1_resized), lo2_resized, lo3), dim=1)\n",
    "        lx3 = self.merge1(lo_features)\n",
    "\n",
    "        lo_features = torch.cat((x3, self.pool(lx3), lo4), dim=1)\n",
    "        lx4 = self.merge2(lo_features)\n",
    "\n",
    "        lo_features = torch.cat((x4, self.pool(lx4), lo5), dim=1)\n",
    "        lx5 = self.merge3(lo_features)\n",
    "\n",
    "        ## Decoder\n",
    "        out = torch.cat((lx5, lo5), dim=1)\n",
    "        out = self.dec5(out)\n",
    "\n",
    "        out = self.upsample(out)\n",
    "        out = torch.cat((out, lx4, lo4), dim=1)\n",
    "        out = self.dec4(out)\n",
    "\n",
    "        out = self.upsample(out)\n",
    "        out = torch.cat((out, lx3, lo3), dim=1)\n",
    "        out = self.dec3(out)\n",
    "\n",
    "        out = self.upsample(out)\n",
    "        out = torch.cat((out, lo2), dim=1)\n",
    "        out = self.dec2(out)\n",
    "\n",
    "        out = self.upsample(out)\n",
    "        out = torch.cat((out, lo1), dim=1)\n",
    "        out = self.dec1(out)\n",
    "\n",
    "\n",
    "        return self.final(out)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Axial\")\n",
    "    model = UMergeNet(in_channels=3, out_channels=1)\n",
    "    x = torch.randn(8, 3, 256, 256)\n",
    "    y = model(x)\n",
    "    print(y.shape)\n",
    "    print(count_trainable_parameters(model, format=True))\n",
    "    fps, time_per_image = measure_inference_speed_v2(model, val_loader)\n",
    "    print(\"FPS:\",fps, \"Time per image:\",time_per_image)\n",
    "\n",
    "    print(\"Axial-DW\")\n",
    "    model = UMergeNet(in_channels=3, out_channels=1, merger_groups='dw', encoder_groups='dw', decoder_groups='dw')\n",
    "    x = torch.randn(8, 3, 256, 256)\n",
    "    y = model(x)\n",
    "    print(y.shape)\n",
    "    print(count_trainable_parameters(model, format=True))\n",
    "    fps, time_per_image = measure_inference_speed_v2(model, val_loader)\n",
    "    print(\"FPS:\",fps, \"Time per image:\",time_per_image)\n",
    "\n",
    "    print(\"Atrous\")\n",
    "    model = UMergeNet(in_channels=3, out_channels=1, conv_type=ConvType.Atrous)\n",
    "    x = torch.randn(8, 3, 256, 256)\n",
    "    y = model(x)\n",
    "    print(y.shape)\n",
    "    print(count_trainable_parameters(model, format=True))\n",
    "    fps, time_per_image = measure_inference_speed_v2(model, val_loader)\n",
    "    print(\"FPS:\",fps, \"Time per image:\",time_per_image)\n",
    "\n",
    "    print(\"Atrous-DW\")\n",
    "    model = UMergeNet(in_channels=3, out_channels=1, conv_type=ConvType.Atrous, merger_groups='dw', encoder_groups='dw', decoder_groups='dw')\n",
    "    x = torch.randn(8, 3, 256, 256)\n",
    "    y = model(x)\n",
    "    print(y.shape)\n",
    "    print(count_trainable_parameters(model, format=True))\n",
    "    fps, time_per_image = measure_inference_speed_v2(model, val_loader)\n",
    "    print(\"FPS:\",fps, \"Time per image:\",time_per_image)\n",
    "\n",
    "    print(\"Normal\")\n",
    "    model = UMergeNet(in_channels=3, out_channels=1, conv_type=ConvType.Standard)\n",
    "    x = torch.randn(8, 3, 256, 256)\n",
    "    y = model(x)\n",
    "    print(y.shape)\n",
    "    print(count_trainable_parameters(model, format=True))\n",
    "    fps, time_per_image = measure_inference_speed_v2(model, val_loader)\n",
    "    print(\"FPS:\",fps, \"Time per image:\",time_per_image)\n",
    "\n",
    "    print(\"Normal-DW\")\n",
    "    model = UMergeNet(in_channels=3, out_channels=1, conv_type=ConvType.Standard, merger_groups='dw', encoder_groups='dw', decoder_groups='dw')\n",
    "    x = torch.randn(8, 3, 256, 256)\n",
    "    y = model(x)\n",
    "    print(y.shape)\n",
    "    print(count_trainable_parameters(model, format=True))\n",
    "    fps, time_per_image = measure_inference_speed_v2(model, val_loader)\n",
    "    print(\"FPS:\",fps, \"Time per image:\",time_per_image)\n",
    "\n",
    "\n",
    "    #REFERENCIA - UMergeNetMergerMoreLayersPerLevel-2\n",
    "    #2.446.673\n",
    "    #GFLOPS: 1.35\n",
    "    # Dice: 0.9412 mIoU: 0.8891\n",
    "    # FPS: 907 Time per image: 1.101 ms\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch5070",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
